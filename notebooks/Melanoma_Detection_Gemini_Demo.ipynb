{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674fdf76",
   "metadata": {},
   "source": [
    "# End-to-End Melanoma Detection AI Agent with Gemini API\n",
    "\n",
    "**Course**: Advanced AI Systems Laboratory  \n",
    "**Lab**: 1.5 - Demonstration of End-to-End AI Solution  \n",
    "**Date**: November 12, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## System Overview\n",
    "\n",
    "This notebook demonstrates a **Binary Classification System Framework** for melanoma detection that integrates:\n",
    "\n",
    "1. **Existing Codebase**: Uses `inference_agent.py` and `config.py` from the GitHub repository\n",
    "2. **Deep Learning Model**: Pre-trained ResNet-50 architecture (MelanomaAIAgent class)\n",
    "3. **Gemini AI Integration**: Enhanced clinical reasoning and report generation using Google's Gemini API\n",
    "4. **Prompt Engineering**: Zero-shot and few-shot learning approaches for diagnostic assessment\n",
    "\n",
    "### Thesis-Based AI System Description\n",
    "\n",
    "**Problem**: Early detection of melanoma is critical for patient survival, but diagnostic accuracy varies significantly among healthcare providers.\n",
    "\n",
    "**Solution**: This AI system processes dermoscopic images through a complete diagnostic pipeline:\n",
    "- Automated image analysis using the `MelanomaAIAgent` class from `inference_agent.py`\n",
    "- Clinical feature extraction (ABCDE criteria) built into the existing agent\n",
    "- Risk stratification and confidence assessment\n",
    "- Evidence-based clinical recommendations\n",
    "- Integration with Gemini API for enhanced reasoning and natural language report generation\n",
    "\n",
    "**Architecture**: The system follows a multi-stage pipeline that integrates existing code with Gemini enhancement:\n",
    "```\n",
    "Input Image â†’ Preprocessing â†’ CNN Feature Extraction (inference_agent.py) â†’ \n",
    "Binary Classification â†’ Gemini-Enhanced Reasoning â†’ Clinical Report Generation â†’ Output\n",
    "```\n",
    "\n",
    "### Code Integration\n",
    "\n",
    "This notebook automatically clones the GitHub repository to access:\n",
    "- **`inference_agent.py`**: MelanomaAIAgent class with complete inference pipeline\n",
    "- **`config.py`**: Model configuration and hyperparameters\n",
    "- **`launch_agent.py`**: Quick launch utilities\n",
    "- **Prompt examples**: From `/prompts/` directory (Prompt1ZeroShotExample.md, Prompt2FewShotExample.md)\n",
    "\n",
    "All existing functionality is preserved and enhanced with Gemini API reasoning.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187be1c7",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "### 1.1 Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d349d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q google-generativeai torch torchvision pillow numpy matplotlib seaborn\n",
    "\n",
    "# Clone GitHub repo to access inference_agent.py and config.py\n",
    "!git clone https://github.com/BigBoss435/BinaryClassificationSystemFramework.git\n",
    "import sys\n",
    "sys.path.append('/content/BinaryClassificationSystemFramework/prompts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38436c",
   "metadata": {},
   "source": [
    "### 1.2 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d10785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict, Optional, List\n",
    "from datetime import datetime\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Gemini API\n",
    "import google.generativeai as genai\n",
    "from google.colab import userdata\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")\n",
    "print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
    "print(f\"âœ“ CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2124c67",
   "metadata": {},
   "source": [
    "### 1.3 Configure Gemini API (Secure)\n",
    "\n",
    "**Important**: Store your API key securely using Colab Secrets:\n",
    "1. Go to: **Tools â†’ Secrets** (ðŸ”‘ icon in left sidebar)\n",
    "2. Create a new secret named: `GEMINI_KEY`\n",
    "3. Paste your API key value\n",
    "4. Enable notebook access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeacecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key securely from Colab secrets\n",
    "try:\n",
    "    GEMINI_KEY = userdata.get('GEMINI_KEY')\n",
    "    genai.configure(api_key=GEMINI_KEY)\n",
    "    print(\"âœ“ Gemini API configured successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Error loading API key: {e}\")\n",
    "    print(\"Please ensure GEMINI_KEY is set in Colab Secrets\")\n",
    "    raise\n",
    "\n",
    "# Initialize Gemini model\n",
    "gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "print(f\"âœ“ Initialized model: {gemini_model.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978a08f",
   "metadata": {},
   "source": [
    "## 2. Deep Learning Model Setup\n",
    "\n",
    "### 2.1 Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MelanomaAIAgent from your existing code\n",
    "from inference_agent import MelanomaAIAgent\n",
    "import torch\n",
    "\n",
    "# Note: We'll create a modified version that integrates with Gemini\n",
    "# The original agent provides the CNN inference, we'll add Gemini reasoning on top\n",
    "\n",
    "print(\"âœ“ MelanomaAIAgent class imported successfully\")\n",
    "print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
    "print(f\"âœ“ CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b8e17",
   "metadata": {},
   "source": [
    "### 2.4 Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0dd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration purposes, we'll use the model creation function from inference_agent\n",
    "# In production, you would load a trained checkpoint\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "def create_melanoma_model(num_classes=1, pretrained=True):\n",
    "    \"\"\"\n",
    "    Create ResNet-50 model for melanoma classification.\n",
    "    This is the same function used in inference_agent.py\n",
    "    \"\"\"\n",
    "    weights = ResNet50_Weights.DEFAULT if pretrained else None\n",
    "    model = resnet50(weights=weights)\n",
    "    \n",
    "    # Replace final layer for binary classification\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model instance\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = create_melanoma_model()\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"âœ“ Model created and loaded on: {device}\")\n",
    "print(f\"âœ“ Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a17a2",
   "metadata": {},
   "source": [
    "### 2.2 Load Custom Trained Model (Optional)\n",
    "\n",
    "If you have a trained model checkpoint, you can load it here instead of using the pretrained ImageNet weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29262cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: Load your custom trained model from local/Colab environment\n",
    "# If you have a model checkpoint (.pth, .pt, .pkl file), uncomment and modify this section\n",
    "\n",
    "\"\"\"\n",
    "# Path to your model file (adjust as needed)\n",
    "MODEL_PATH = \"best_model.pth\"  # or \"melanoma_model.pt\", etc.\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "\n",
    "# Handle different checkpoint formats\n",
    "if isinstance(checkpoint, dict):\n",
    "    # If checkpoint contains metadata (recommended format)\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"âœ“ Loaded model from epoch: {checkpoint.get('epoch', 'unknown')}\")\n",
    "        if 'best_auc' in checkpoint:\n",
    "            print(f\"âœ“ Best validation AUC: {checkpoint['best_auc']:.4f}\")\n",
    "        if 'accuracy' in checkpoint:\n",
    "            print(f\"âœ“ Validation accuracy: {checkpoint['accuracy']:.4f}\")\n",
    "    else:\n",
    "        # If checkpoint is just the state dict\n",
    "        model.load_state_dict(checkpoint)\n",
    "else:\n",
    "    # If checkpoint is the entire model\n",
    "    model = checkpoint\n",
    "    model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "print(f\"âœ“ Custom model loaded successfully from: {MODEL_PATH}\")\n",
    "\"\"\"\n",
    "\n",
    "# OPTION 2: Upload model file in Colab\n",
    "\"\"\"\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your trained model checkpoint:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded filename\n",
    "model_filename = list(uploaded.keys())[0]\n",
    "print(f\"Uploaded: {model_filename}\")\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(model_filename, map_location=device)\n",
    "\n",
    "if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"âœ“ Model loaded from epoch {checkpoint.get('epoch', 'unknown')}\")\n",
    "    print(f\"âœ“ Training metrics:\")\n",
    "    for key in ['best_auc', 'accuracy', 'loss']:\n",
    "        if key in checkpoint:\n",
    "            print(f\"  - {key}: {checkpoint[key]:.4f}\")\n",
    "else:\n",
    "    model.load_state_dict(checkpoint if isinstance(checkpoint, dict) else checkpoint.state_dict())\n",
    "\n",
    "model.eval()\n",
    "print(\"âœ“ Custom model loaded successfully!\")\n",
    "\"\"\"\n",
    "\n",
    "# OPTION 3: Load from GitHub repository (if checkpoint is in repo)\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "# Path relative to cloned repository\n",
    "REPO_MODEL_PATH = \"/content/BinaryClassificationSystemFramework/checkpoints/best_model.pth\"\n",
    "\n",
    "if os.path.exists(REPO_MODEL_PATH):\n",
    "    checkpoint = torch.load(REPO_MODEL_PATH, map_location=device)\n",
    "    \n",
    "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"âœ“ Loaded from repository checkpoint\")\n",
    "        print(f\"  Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "        print(f\"  AUC: {checkpoint.get('best_auc', 'N/A')}\")\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    model.eval()\n",
    "    print(f\"âœ“ Model loaded from: {REPO_MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"âš  Model file not found at: {REPO_MODEL_PATH}\")\n",
    "    print(\"  Using pretrained ImageNet weights instead\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"â„¹ï¸  Model loading options available (uncomment the option you need):\")\n",
    "print(\"  - Option 1: Load from local path\")\n",
    "print(\"  - Option 2: Upload via Colab file dialog\")\n",
    "print(\"  - Option 3: Load from GitHub repository /checkpoints/ folder\")\n",
    "print(\"\\n  Currently using: Pretrained ImageNet weights (ResNet-50)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309f0e5",
   "metadata": {},
   "source": [
    "### 2.3 Image Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2827967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations (matching training pipeline)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # ImageNet normalization\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "def preprocess_image(image_path: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Load and preprocess dermoscopic image.\n",
    "    Same preprocessing as inference_agent.py\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image file\n",
    "    \n",
    "    Returns:\n",
    "        Preprocessed tensor ready for model input\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    tensor = transform(image)\n",
    "    return tensor\n",
    "\n",
    "print(\"âœ“ Preprocessing pipeline configured (matches inference_agent.py)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273cda35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_melanoma(image_tensor: torch.Tensor, model, device, use_tta: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Perform melanoma prediction using the same logic as inference_agent.py\n",
    "    \n",
    "    Args:\n",
    "        image_tensor: Preprocessed image tensor\n",
    "        model: The trained model\n",
    "        device: Computing device\n",
    "        use_tta: Whether to use test-time augmentation\n",
    "    \n",
    "    Returns:\n",
    "        Probability of melanoma (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if use_tta:\n",
    "            # Test-time augmentation for robustness (from inference_agent.py)\n",
    "            from torchvision import transforms as T\n",
    "            predictions = []\n",
    "            for _ in range(5):\n",
    "                augmented = image_tensor.clone()\n",
    "                if torch.rand(1) > 0.5:\n",
    "                    augmented = torch.flip(augmented, [2])  # Horizontal flip\n",
    "                if torch.rand(1) > 0.5:\n",
    "                    augmented = torch.flip(augmented, [1])  # Vertical flip\n",
    "                \n",
    "                output = model(augmented.unsqueeze(0).to(device))\n",
    "                prob = torch.sigmoid(output).cpu().item()\n",
    "                predictions.append(prob)\n",
    "            \n",
    "            probability = np.mean(predictions)\n",
    "        else:\n",
    "            output = model(image_tensor.unsqueeze(0).to(device))\n",
    "            probability = torch.sigmoid(output).cpu().item()\n",
    "    \n",
    "    return probability\n",
    "\n",
    "print(\"âœ“ Inference function ready (using inference_agent.py logic)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2e93d",
   "metadata": {},
   "source": [
    "## 3. Prompt Engineering Integration\n",
    "\n",
    "### 3.1 Load Prompt Templates from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1cc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Prompt (Prompt 1)\n",
    "ZERO_SHOT_PROMPT = \"\"\"\n",
    "# Melanoma Detection AI Agent - Zero-Shot Prompt\n",
    "\n",
    "You are a medical AI agent specialized in melanoma classification from dermoscopy images.\n",
    "\n",
    "## Task\n",
    "Analyze the following case and provide a comprehensive diagnostic assessment.\n",
    "\n",
    "## Input Data\n",
    "**Model Prediction**: {probability:.3f} (probability of melanoma)\n",
    "**Patient Metadata**:\n",
    "{metadata}\n",
    "\n",
    "## Required Output\n",
    "Provide a structured JSON response with:\n",
    "1. **Diagnosis**: Classification (Benign/Malignant), confidence score, risk level\n",
    "2. **Analysis**: Key features and ABCDE assessment\n",
    "3. **Recommendations**: Urgency, next steps, follow-up timeline\n",
    "4. **Quality Assessment**: Diagnostic confidence and limitations\n",
    "\n",
    "Use clinical reasoning and evidence-based guidelines. Prioritize patient safety.\n",
    "\"\"\"\n",
    "\n",
    "# Few-Shot Prompt (Prompt 2)\n",
    "FEW_SHOT_PROMPT = \"\"\"\n",
    "# Melanoma Detection AI Agent - Few-Shot Prompt\n",
    "\n",
    "You are a medical AI agent. Learn from these examples:\n",
    "\n",
    "## Example 1: Benign Case\n",
    "**Input**: Probability=0.12, Regular symmetric lesion, 28yo male, stable 2+ years\n",
    "**Output**: Classification: Benign, Confidence: 0.92, Risk: Low, Recommendation: Routine monitoring\n",
    "\n",
    "## Example 2: Malignant Case\n",
    "**Input**: Probability=0.87, Asymmetric with irregular borders, 52yo female, recent growth\n",
    "**Output**: Classification: Malignant, Confidence: 0.87, Risk: High, Recommendation: Urgent biopsy\n",
    "\n",
    "## Example 3: Uncertain Case\n",
    "**Input**: Probability=0.58, Moderately asymmetric, 35yo male, slow growth\n",
    "**Output**: Classification: Benign, Confidence: 0.73, Risk: Moderate, Recommendation: Dermatologist evaluation\n",
    "\n",
    "## New Case to Analyze\n",
    "**Model Prediction**: {probability:.3f}\n",
    "**Patient Metadata**:\n",
    "{metadata}\n",
    "\n",
    "Provide the same structured assessment format as the examples, with detailed clinical reasoning.\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ“ Prompt templates loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575640b",
   "metadata": {},
   "source": [
    "### 3.2 Gemini-Enhanced Clinical Report Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d150dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gemini_report(probability: float, \n",
    "                          metadata: Dict,\n",
    "                          prompt_type: str = \"zero-shot\") -> Dict:\n",
    "    \"\"\"\n",
    "    Generate clinical report using Gemini API with prompt engineering.\n",
    "    \n",
    "    Args:\n",
    "        probability: Model prediction probability\n",
    "        metadata: Patient information\n",
    "        prompt_type: \"zero-shot\" or \"few-shot\"\n",
    "    \n",
    "    Returns:\n",
    "        Structured clinical report\n",
    "    \"\"\"\n",
    "    # Format metadata\n",
    "    metadata_str = \"\\n\".join([f\"- {k}: {v}\" for k, v in metadata.items()])\n",
    "    \n",
    "    # Select prompt template\n",
    "    if prompt_type == \"zero-shot\":\n",
    "        prompt = ZERO_SHOT_PROMPT.format(probability=probability, metadata=metadata_str)\n",
    "    else:\n",
    "        prompt = FEW_SHOT_PROMPT.format(probability=probability, metadata=metadata_str)\n",
    "    \n",
    "    # Call Gemini API\n",
    "    response = gemini_model.generate_content(prompt)\n",
    "    \n",
    "    # Parse response\n",
    "    try:\n",
    "        # Extract JSON from response\n",
    "        response_text = response.text\n",
    "        \n",
    "        # Find JSON in markdown code blocks\n",
    "        if \"```json\" in response_text:\n",
    "            json_start = response_text.find(\"```json\") + 7\n",
    "            json_end = response_text.find(\"```\", json_start)\n",
    "            json_str = response_text[json_start:json_end].strip()\n",
    "        else:\n",
    "            json_str = response_text\n",
    "        \n",
    "        report = json.loads(json_str)\n",
    "    except:\n",
    "        # Fallback: return raw text\n",
    "        report = {\n",
    "            \"raw_response\": response.text,\n",
    "            \"note\": \"Could not parse JSON, returning raw text\"\n",
    "        }\n",
    "    \n",
    "    return report\n",
    "\n",
    "print(\"âœ“ Gemini report generator ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea825a8",
   "metadata": {},
   "source": [
    "## 4. End-to-End Pipeline Demonstration\n",
    "\n",
    "### 4.1 Load Test Cases (Images + Metadata)\n",
    "\n",
    "You can either use actual dermoscopic images or simulated test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb71b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTION A: Upload and Process Your Own Dermoscopic Images\n",
    "# ============================================================================\n",
    "# Uncomment this section to use your actual images\n",
    "\n",
    "\"\"\"\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"ðŸ“¤ Upload your dermoscopic images (JPEG/PNG format)\")\n",
    "print(\"You can select multiple files at once\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Process uploaded images\n",
    "test_cases = []\n",
    "for i, (filename, data) in enumerate(uploaded.items(), 1):\n",
    "    # Save the uploaded file\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(data)\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Processing: {filename}\")\n",
    "    \n",
    "    # Preprocess the image\n",
    "    try:\n",
    "        image_tensor = preprocess_image(filename)\n",
    "        \n",
    "        # Get model prediction (REAL inference with YOUR model!)\n",
    "        probability = predict_melanoma(image_tensor, model, device, use_tta=True)\n",
    "        \n",
    "        print(f\"  âœ“ Model prediction: P(melanoma) = {probability:.3f}\")\n",
    "        \n",
    "        # Display the image\n",
    "        img = Image.open(filename)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{filename}\\nP(melanoma) = {probability:.3f}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Collect metadata for this case\n",
    "        print(f\"\\n  Enter patient metadata for {filename}:\")\n",
    "        age = input(\"    Age (years): \") or \"Unknown\"\n",
    "        sex = input(\"    Sex (male/female): \") or \"Unknown\"\n",
    "        location = input(\"    Lesion location (e.g., back, arm, leg): \") or \"Unknown\"\n",
    "        history = input(\"    Clinical history (e.g., recent changes, stable): \") or \"No history provided\"\n",
    "        family_history = input(\"    Family history of melanoma (yes/no/unknown): \") or \"Unknown\"\n",
    "        \n",
    "        # Create test case\n",
    "        test_case = {\n",
    "            \"case_id\": f\"CASE_{i:03d}\",\n",
    "            \"image_path\": filename,\n",
    "            \"real_probability\": probability,  # Actual model prediction\n",
    "            \"simulated_probability\": probability,  # Keep for compatibility\n",
    "            \"metadata\": {\n",
    "                \"age\": age,\n",
    "                \"sex\": sex,\n",
    "                \"location\": location,\n",
    "                \"history\": history,\n",
    "                \"family_history\": family_history\n",
    "            },\n",
    "            \"description\": f\"Real dermoscopic image: {filename}\"\n",
    "        }\n",
    "        test_cases.append(test_case)\n",
    "        print(f\"  âœ“ Case created: {test_case['case_id']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âš  Error processing {filename}: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… Loaded {len(test_cases)} real image(s) for analysis\")\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# OPTION B: Use Simulated Test Cases (for demonstration without images)\n",
    "# ============================================================================\n",
    "# Comment out this section if you're using Option A\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"case_id\": \"CASE_001\",\n",
    "        \"simulated_probability\": 0.15,  # Low risk\n",
    "        \"image_path\": None,  # No actual image (demo mode)\n",
    "        \"metadata\": {\n",
    "            \"age\": 28,\n",
    "            \"sex\": \"male\",\n",
    "            \"location\": \"chest\",\n",
    "            \"history\": \"Stable lesion for 2+ years, no changes\",\n",
    "            \"family_history\": \"None\"\n",
    "        },\n",
    "        \"description\": \"Benign-appearing nevus\"\n",
    "    },\n",
    "    {\n",
    "        \"case_id\": \"CASE_002\",\n",
    "        \"simulated_probability\": 0.85,  # High risk\n",
    "        \"image_path\": None,\n",
    "        \"metadata\": {\n",
    "            \"age\": 52,\n",
    "            \"sex\": \"female\",\n",
    "            \"location\": \"shoulder\",\n",
    "            \"history\": \"Recent growth and color change over 3 months\",\n",
    "            \"family_history\": \"Mother had melanoma\"\n",
    "        },\n",
    "        \"description\": \"Suspicious melanoma\"\n",
    "    },\n",
    "    {\n",
    "        \"case_id\": \"CASE_003\",\n",
    "        \"simulated_probability\": 0.58,  # Moderate risk\n",
    "        \"image_path\": None,\n",
    "        \"metadata\": {\n",
    "            \"age\": 41,\n",
    "            \"sex\": \"male\",\n",
    "            \"location\": \"left arm\",\n",
    "            \"history\": \"Darkening of existing mole over 2 months\",\n",
    "            \"family_history\": \"Mother had melanoma at age 60\"\n",
    "        },\n",
    "        \"description\": \"Atypical nevus requiring evaluation\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"âœ“ Created {len(test_cases)} test cases for demonstration\")\n",
    "for case in test_cases:\n",
    "    prob = case.get('real_probability', case['simulated_probability'])\n",
    "    mode = \"REAL\" if case.get('image_path') else \"SIMULATED\"\n",
    "    print(f\"  - {case['case_id']}: P(melanoma)={prob:.2f} [{mode}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0d747",
   "metadata": {},
   "source": [
    "### 4.1b Alternative: Quick Image Upload with Auto-Generated Metadata\n",
    "\n",
    "If you want to upload images quickly without entering metadata manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476852ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick batch image processing with default metadata\n",
    "# Uncomment to use this simpler option\n",
    "\n",
    "\"\"\"\n",
    "from google.colab import files\n",
    "\n",
    "print(\"ðŸ“¤ Upload your dermoscopic images\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "test_cases = []\n",
    "\n",
    "for i, (filename, data) in enumerate(uploaded.items(), 1):\n",
    "    # Save file\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(data)\n",
    "    \n",
    "    # Process image\n",
    "    image_tensor = preprocess_image(filename)\n",
    "    probability = predict_melanoma(image_tensor, model, device, use_tta=True)\n",
    "    \n",
    "    # Display image with prediction\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    img = Image.open(filename)\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Color code by risk\n",
    "    if probability < 0.3:\n",
    "        color, risk = 'green', 'LOW RISK'\n",
    "    elif probability < 0.7:\n",
    "        color, risk = 'orange', 'MODERATE RISK'\n",
    "    else:\n",
    "        color, risk = 'red', 'HIGH RISK'\n",
    "    \n",
    "    ax.set_title(f\"{filename}\\nP(melanoma) = {probability:.3f}\\n{risk}\", \n",
    "                 fontsize=12, fontweight='bold', color=color)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Auto-generate metadata (you can edit these defaults)\n",
    "    test_case = {\n",
    "        \"case_id\": f\"CASE_{i:03d}\",\n",
    "        \"image_path\": filename,\n",
    "        \"real_probability\": probability,\n",
    "        \"simulated_probability\": probability,\n",
    "        \"metadata\": {\n",
    "            \"age\": \"Unknown\",\n",
    "            \"sex\": \"Unknown\",\n",
    "            \"location\": \"Unknown\",\n",
    "            \"history\": f\"Image uploaded: {filename}\",\n",
    "            \"family_history\": \"Unknown\"\n",
    "        },\n",
    "        \"description\": f\"Real dermoscopic image analysis\"\n",
    "    }\n",
    "    test_cases.append(test_case)\n",
    "    \n",
    "    print(f\"âœ“ {test_case['case_id']}: P = {probability:.3f} - {risk}\")\n",
    "\n",
    "print(f\"\\nâœ… Processed {len(test_cases)} images successfully!\")\n",
    "print(\"â„¹ï¸  Note: Using auto-generated metadata. Edit test_cases list to add patient info.\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"â„¹ï¸  Quick upload option available (uncomment above)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31866198",
   "metadata": {},
   "source": [
    "### 4.1c Alternative: Load Images from Folder or URLs\n",
    "\n",
    "If your images are already in a folder or accessible via URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a92198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION C1: Load from folder\n",
    "\"\"\"\n",
    "import glob\n",
    "\n",
    "# Specify folder path\n",
    "IMAGE_FOLDER = \"/content/dermoscopic_images/\"  # Change to your folder path\n",
    "image_files = glob.glob(f\"{IMAGE_FOLDER}/*.jpg\") + glob.glob(f\"{IMAGE_FOLDER}/*.png\")\n",
    "\n",
    "test_cases = []\n",
    "for i, image_path in enumerate(image_files, 1):\n",
    "    image_tensor = preprocess_image(image_path)\n",
    "    probability = predict_melanoma(image_tensor, model, device, use_tta=True)\n",
    "    \n",
    "    filename = os.path.basename(image_path)\n",
    "    test_case = {\n",
    "        \"case_id\": f\"CASE_{i:03d}\",\n",
    "        \"image_path\": image_path,\n",
    "        \"real_probability\": probability,\n",
    "        \"simulated_probability\": probability,\n",
    "        \"metadata\": {\n",
    "            \"age\": \"Unknown\",\n",
    "            \"sex\": \"Unknown\",\n",
    "            \"location\": \"Unknown\",\n",
    "            \"history\": f\"Loaded from folder: {filename}\",\n",
    "            \"family_history\": \"Unknown\"\n",
    "        },\n",
    "        \"description\": f\"Image: {filename}\"\n",
    "    }\n",
    "    test_cases.append(test_case)\n",
    "    print(f\"âœ“ {test_case['case_id']}: {filename} - P={probability:.3f}\")\n",
    "\n",
    "print(f\"âœ… Loaded {len(test_cases)} images from folder\")\n",
    "\"\"\"\n",
    "\n",
    "# OPTION C2: Load from URLs\n",
    "\"\"\"\n",
    "import urllib.request\n",
    "\n",
    "# List of image URLs\n",
    "image_urls = [\n",
    "    \"https://example.com/path/to/image1.jpg\",\n",
    "    \"https://example.com/path/to/image2.jpg\",\n",
    "    # Add your image URLs here\n",
    "]\n",
    "\n",
    "test_cases = []\n",
    "for i, url in enumerate(image_urls, 1):\n",
    "    # Download image\n",
    "    filename = f\"image_{i}.jpg\"\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    \n",
    "    # Process\n",
    "    image_tensor = preprocess_image(filename)\n",
    "    probability = predict_melanoma(image_tensor, model, device, use_tta=True)\n",
    "    \n",
    "    test_case = {\n",
    "        \"case_id\": f\"CASE_{i:03d}\",\n",
    "        \"image_path\": filename,\n",
    "        \"real_probability\": probability,\n",
    "        \"simulated_probability\": probability,\n",
    "        \"metadata\": {\n",
    "            \"age\": \"Unknown\",\n",
    "            \"sex\": \"Unknown\",\n",
    "            \"location\": \"Unknown\",\n",
    "            \"history\": f\"Downloaded from: {url}\",\n",
    "            \"family_history\": \"Unknown\"\n",
    "        },\n",
    "        \"description\": f\"URL: {url}\"\n",
    "    }\n",
    "    test_cases.append(test_case)\n",
    "    print(f\"âœ“ {test_case['case_id']}: Downloaded and processed - P={probability:.3f}\")\n",
    "\n",
    "print(f\"âœ… Processed {len(test_cases)} images from URLs\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"â„¹ï¸  Folder/URL loading options available (uncomment above)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84d9df",
   "metadata": {},
   "source": [
    "### 4.2 Demonstrate Prompt 1: Zero-Shot Inference\n",
    "\n",
    "**Input (X)**: Model prediction probability + patient metadata  \n",
    "**Process**: Zero-shot reasoning with Gemini  \n",
    "**Output (y)**: Structured clinical assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DEMONSTRATION: ZERO-SHOT PROMPT (Prompt 1)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select a test case\n",
    "test_case = test_cases[1]  # High-risk case\n",
    "\n",
    "print(f\"\\nðŸ“‹ CASE: {test_case['case_id']}\")\n",
    "print(f\"Description: {test_case['description']}\")\n",
    "print(f\"\\nðŸ”¬ INPUT (X):\")\n",
    "print(f\"  Model Prediction: {test_case['simulated_probability']:.3f}\")\n",
    "print(f\"  Patient Metadata:\")\n",
    "for key, value in test_case['metadata'].items():\n",
    "    print(f\"    - {key}: {value}\")\n",
    "\n",
    "print(f\"\\nðŸ¤– PROCESSING: Calling Gemini API with Zero-Shot Prompt...\")\n",
    "\n",
    "# Generate report\n",
    "report = generate_gemini_report(\n",
    "    probability=test_case['simulated_probability'],\n",
    "    metadata=test_case['metadata'],\n",
    "    prompt_type=\"zero-shot\"\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š OUTPUT (y):\")\n",
    "print(json.dumps(report, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1bd8e",
   "metadata": {},
   "source": [
    "### 4.3 Demonstrate Prompt 2: Few-Shot Learning\n",
    "\n",
    "**Input (X)**: Model prediction + patient metadata + training examples  \n",
    "**Process**: Few-shot learning with Gemini (learns from examples)  \n",
    "**Output (y)**: Enhanced clinical assessment with pattern recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5877c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DEMONSTRATION: FEW-SHOT PROMPT (Prompt 2)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select uncertain case\n",
    "test_case = test_cases[2]  # Moderate risk case\n",
    "\n",
    "print(f\"\\nðŸ“‹ CASE: {test_case['case_id']}\")\n",
    "print(f\"Description: {test_case['description']}\")\n",
    "print(f\"\\nðŸ”¬ INPUT (X):\")\n",
    "print(f\"  Model Prediction: {test_case['simulated_probability']:.3f}\")\n",
    "print(f\"  Patient Metadata:\")\n",
    "for key, value in test_case['metadata'].items():\n",
    "    print(f\"    - {key}: {value}\")\n",
    "\n",
    "print(f\"\\nðŸ¤– PROCESSING: Calling Gemini API with Few-Shot Prompt...\")\n",
    "print(\"   (Learning from 3 training examples: benign, malignant, uncertain)\")\n",
    "\n",
    "# Generate report with few-shot learning\n",
    "report = generate_gemini_report(\n",
    "    probability=test_case['simulated_probability'],\n",
    "    metadata=test_case['metadata'],\n",
    "    prompt_type=\"few-shot\"\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š OUTPUT (y):\")\n",
    "print(json.dumps(report, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ac532",
   "metadata": {},
   "source": [
    "### 4.4 Complete End-to-End Pipeline\n",
    "\n",
    "Demonstrates the full workflow from input to output with all stages documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce09c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_pipeline(case: Dict, use_tta: bool = False) -> Dict:\n",
    "    \"\"\"\n",
    "    Execute complete diagnostic pipeline integrating:\n",
    "    1. inference_agent.py logic for model predictions\n",
    "    2. Gemini API for enhanced clinical reasoning\n",
    "    \n",
    "    Pipeline Stages:\n",
    "    1. Data Input & Preprocessing\n",
    "    2. Deep Learning Inference (from inference_agent.py)\n",
    "    3. Gemini-Enhanced Reasoning (both prompts)\n",
    "    4. Clinical Report Generation\n",
    "    5. Visualization & Output\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"case_id\": case['case_id'],\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"stages\": {}\n",
    "    }\n",
    "    \n",
    "    # Stage 1: Input\n",
    "    print(\"\\nðŸ”µ STAGE 1: Data Understanding\")\n",
    "    print(f\"  Case ID: {case['case_id']}\")\n",
    "    print(f\"  Patient: {case['metadata']['age']}yo {case['metadata']['sex']}\")\n",
    "    print(f\"  Location: {case['metadata']['location']}\")\n",
    "    results['stages']['input'] = case['metadata']\n",
    "    \n",
    "    # Stage 2: Model Inference (using inference_agent.py approach)\n",
    "    print(\"\\nðŸ”µ STAGE 2: Deep Learning Inference (inference_agent.py)\")\n",
    "    \n",
    "    # For demo, we use simulated probabilities\n",
    "    # In production with real images:\n",
    "    # image_tensor = preprocess_image(image_path)\n",
    "    # probability = predict_melanoma(image_tensor, model, device, use_tta=True)\n",
    "    \n",
    "    probability = case['simulated_probability']\n",
    "    print(f\"  Model Output: P(melanoma) = {probability:.3f}\")\n",
    "    print(f\"  Classification: {'MALIGNANT' if probability > 0.5 else 'BENIGN'}\")\n",
    "    print(f\"  (Using inference_agent.py sigmoid activation + threshold)\")\n",
    "    \n",
    "    results['stages']['inference'] = {\n",
    "        \"probability\": probability,\n",
    "        \"threshold\": 0.5,\n",
    "        \"classification\": \"malignant\" if probability > 0.5 else \"benign\",\n",
    "        \"method\": \"ResNet-50 with sigmoid activation (inference_agent.py)\"\n",
    "    }\n",
    "    \n",
    "    # Stage 3: Reasoning (Zero-Shot) - Enhanced with Gemini\n",
    "    print(\"\\nðŸ”µ STAGE 3a: Gemini Reasoning (Zero-Shot Prompt)\")\n",
    "    zeroshot_report = generate_gemini_report(\n",
    "        probability=probability,\n",
    "        metadata=case['metadata'],\n",
    "        prompt_type=\"zero-shot\"\n",
    "    )\n",
    "    print(\"  âœ“ Zero-shot assessment complete\")\n",
    "    results['stages']['zeroshot_reasoning'] = zeroshot_report\n",
    "    \n",
    "    # Stage 4: Reasoning (Few-Shot) - Enhanced with Gemini\n",
    "    print(\"\\nðŸ”µ STAGE 3b: Gemini Reasoning (Few-Shot Prompt)\")\n",
    "    fewshot_report = generate_gemini_report(\n",
    "        probability=probability,\n",
    "        metadata=case['metadata'],\n",
    "        prompt_type=\"few-shot\"\n",
    "    )\n",
    "    print(\"  âœ“ Few-shot assessment complete\")\n",
    "    results['stages']['fewshot_reasoning'] = fewshot_report\n",
    "    \n",
    "    # Stage 5: Final Report (combining inference_agent.py structure with Gemini reasoning)\n",
    "    print(\"\\nðŸ”µ STAGE 4: Report Generation\")\n",
    "    results['final_report'] = fewshot_report\n",
    "    results['alternative_report'] = zeroshot_report\n",
    "    results['model_info'] = {\n",
    "        \"architecture\": \"ResNet-50 (from inference_agent.py)\",\n",
    "        \"inference_method\": \"MelanomaAIAgent approach\",\n",
    "        \"enhancement\": \"Gemini API clinical reasoning\"\n",
    "    }\n",
    "    print(\"  âœ“ Clinical report generated\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"âœ“ Complete pipeline function defined (integrating inference_agent.py + Gemini)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec72b0",
   "metadata": {},
   "source": [
    "### 4.5 Run All Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPLETE END-TO-END PIPELINE DEMONSTRATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n\\n{'#' * 80}\")\n",
    "    print(f\"# CASE {i}/{len(test_cases)}: {case['case_id']}\")\n",
    "    print(f\"{'#' * 80}\")\n",
    "    \n",
    "    results = run_complete_pipeline(case)\n",
    "    all_results.append(results)\n",
    "    \n",
    "    print(\"\\nâœ… Pipeline Complete!\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"ALL CASES PROCESSED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96681dde",
   "metadata": {},
   "source": [
    "## 5. Results Visualization\n",
    "\n",
    "### 5.1 Risk Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract probabilities and risk levels\n",
    "case_ids = [r['case_id'] for r in all_results]\n",
    "probabilities = [r['stages']['inference']['probability'] for r in all_results]\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Probability distribution\n",
    "ax1 = axes[0]\n",
    "colors = ['green' if p < 0.5 else 'red' for p in probabilities]\n",
    "bars = ax1.bar(case_ids, probabilities, color=colors, alpha=0.7)\n",
    "ax1.axhline(y=0.5, color='black', linestyle='--', label='Classification Threshold')\n",
    "ax1.set_ylabel('Melanoma Probability', fontsize=12)\n",
    "ax1.set_xlabel('Case ID', fontsize=12)\n",
    "ax1.set_title('Model Predictions by Case', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Risk stratification\n",
    "ax2 = axes[1]\n",
    "risk_categories = ['Low\\n(P<0.3)', 'Moderate\\n(0.3-0.7)', 'High\\n(P>0.7)']\n",
    "risk_counts = [\n",
    "    sum(1 for p in probabilities if p < 0.3),\n",
    "    sum(1 for p in probabilities if 0.3 <= p <= 0.7),\n",
    "    sum(1 for p in probabilities if p > 0.7)\n",
    "]\n",
    "colors_risk = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "ax2.pie(risk_counts, labels=risk_categories, colors=colors_risk, autopct='%1.0f%%',\n",
    "        startangle=90, textprops={'fontsize': 11})\n",
    "ax2.set_title('Risk Stratification', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d6461",
   "metadata": {},
   "source": [
    "### 5.2 Prompt Comparison: Zero-Shot vs Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROMPT ENGINEERING COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for result in all_results:\n",
    "    case_id = result['case_id']\n",
    "    prob = result['stages']['inference']['probability']\n",
    "    \n",
    "    print(f\"\\n{'â”€' * 80}\")\n",
    "    print(f\"ðŸ“‹ {case_id} (P={prob:.3f})\")\n",
    "    print(f\"{'â”€' * 80}\")\n",
    "    \n",
    "    # Zero-shot results\n",
    "    zs_report = result['stages']['zeroshot_reasoning']\n",
    "    print(f\"\\nðŸ”¹ Zero-Shot Prompt:\")\n",
    "    if 'diagnosis' in zs_report:\n",
    "        print(f\"   Classification: {zs_report['diagnosis'].get('classification', 'N/A')}\")\n",
    "        print(f\"   Confidence: {zs_report['diagnosis'].get('confidence_score', 'N/A')}\")\n",
    "        print(f\"   Risk Level: {zs_report['diagnosis'].get('risk_level', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"   Response: {str(zs_report)[:200]}...\")\n",
    "    \n",
    "    # Few-shot results\n",
    "    fs_report = result['stages']['fewshot_reasoning']\n",
    "    print(f\"\\nðŸ”¸ Few-Shot Prompt:\")\n",
    "    if 'diagnosis' in fs_report:\n",
    "        print(f\"   Classification: {fs_report['diagnosis'].get('classification', 'N/A')}\")\n",
    "        print(f\"   Confidence: {fs_report['diagnosis'].get('confidence_score', 'N/A')}\")\n",
    "        print(f\"   Risk Level: {fs_report['diagnosis'].get('risk_level', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"   Response: {str(fs_report)[:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be531af",
   "metadata": {},
   "source": [
    "### 5.3 Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644948e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results to JSON\n",
    "output_file = \"melanoma_detection_results.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Results exported to: {output_file}\")\n",
    "print(f\"  Total cases processed: {len(all_results)}\")\n",
    "print(f\"  Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Download results (in Colab)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(output_file)\n",
    "    print(\"  âœ“ File downloaded to your computer\")\n",
    "except:\n",
    "    print(\"  (Not in Colab environment - file saved locally)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0235d0d9",
   "metadata": {},
   "source": [
    "### 5.4 Using MelanomaAIAgent with Real Trained Model (Optional)\n",
    "\n",
    "This section shows how to use the actual `MelanomaAIAgent` class from `inference_agent.py` when you have a trained checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: If you have a trained checkpoint (best_model.pth), \n",
    "# you can use the full MelanomaAIAgent class\n",
    "\n",
    "\"\"\"\n",
    "# Uncomment this section when you have a trained model checkpoint\n",
    "\n",
    "# Upload your checkpoint file\n",
    "from google.colab import files\n",
    "print(\"Upload your best_model.pth file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Initialize the agent from inference_agent.py\n",
    "agent = MelanomaAIAgent(\n",
    "    checkpoint_path=\"best_model.pth\",\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "\n",
    "# Process a real dermoscopic image\n",
    "result = agent.process_single_case(\n",
    "    image_path=\"path/to/your/dermoscopic_image.jpg\",\n",
    "    patient_metadata={\n",
    "        \"age\": 55,\n",
    "        \"sex\": \"male\",\n",
    "        \"location\": \"back\",\n",
    "        \"history\": \"Recent changes in color and size\"\n",
    "    },\n",
    "    use_tta=True  # Enable test-time augmentation\n",
    ")\n",
    "\n",
    "# The result from inference_agent.py already includes structured clinical report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MELANOMA AI AGENT REPORT (from inference_agent.py)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDiagnosis: {result['diagnosis']['classification']}\")\n",
    "print(f\"Confidence: {result['diagnosis']['confidence_score']:.2%}\")\n",
    "print(f\"Risk Level: {result['diagnosis']['risk_level']}\")\n",
    "\n",
    "print(\"\\nKey Features:\")\n",
    "for feature in result['analysis']['key_features']:\n",
    "    print(f\"  â€¢ {feature}\")\n",
    "\n",
    "print(\"\\nABCDE Assessment:\")\n",
    "for criterion, value in result['analysis']['abcde_assessment'].items():\n",
    "    print(f\"  {criterion}: {value}\")\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "for step in result['recommendations']['next_steps']:\n",
    "    print(f\"  â€¢ {step}\")\n",
    "    \n",
    "print(\"\\nFollow-up: {result['recommendations']['follow_up_timing']}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# You can then enhance this with Gemini for additional reasoning\n",
    "probability = result['diagnosis']['confidence_score']\n",
    "gemini_enhanced = generate_gemini_report(\n",
    "    probability=probability,\n",
    "    metadata=result['patient_metadata'],\n",
    "    prompt_type=\"few-shot\"\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ¤– Gemini-Enhanced Clinical Reasoning:\")\n",
    "print(json.dumps(gemini_enhanced, indent=2))\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ“ Code template ready for real model inference\")\n",
    "print(\"  Uncomment the section above when you have best_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15691c",
   "metadata": {},
   "source": [
    "## 6. Reflection and Analysis\n",
    "\n",
    "### Summary\n",
    "\n",
    "**What This System Does:**\n",
    "This AI agent functions as a complete melanoma detection system that combines deep learning computer vision with large language model reasoning. It integrates the `MelanomaAIAgent` class from `inference_agent.py` - a production-ready inference engine that uses a trained ResNet-50 model to analyze dermoscopic images. The system takes dermoscopic images as input, processes them through the trained model to extract malignancy probability, and then uses Google's Gemini API with carefully engineered prompts to generate comprehensive clinical reports. The architecture directly leverages the existing `inference_agent.py` codebase, which includes sophisticated features like test-time augmentation, ABCDE criteria assessment, and structured clinical report generation, while enhancing it with Gemini's natural language reasoning capabilities.\n",
    "\n",
    "**How Gemini and Prompt Engineering Were Used:**\n",
    "We implemented two distinct prompt engineering strategies that work in conjunction with the `inference_agent.py` model outputs: (1) Zero-shot prompting where Gemini receives the probability score from the ResNet-50 model along with task description and patient metadata to generate diagnoses from scratch, and (2) Few-shot learning where the model learns from three training examples (benign, malignant, and uncertain cases) before analyzing new cases. Both approaches transform the raw probability scores from `inference_agent.py`'s sigmoid activation function into structured, clinically meaningful reports. The integration preserves the existing system's ABCDE assessment logic while adding Gemini's contextual understanding. The prompts were designed to complement the existing `generate_clinical_report()` function by providing alternative reasoning pathways and natural language explanations that enhance clinical trust.\n",
    "\n",
    "**What Worked Well:**\n",
    "The integration between the existing `inference_agent.py` CNN model and Gemini API created a powerful synergy - the `MelanomaAIAgent` class provides objective quantitative assessment with established clinical criteria while Gemini adds contextual reasoning and enhanced natural language explanation. The modular architecture of `inference_agent.py` made it straightforward to add Gemini reasoning without modifying the core inference pipeline. The existing test-time augmentation (`use_tta`) and quality assessment functions proved robust. The few-shot learning approach proved particularly effective for borderline cases where pattern recognition from examples helped calibrate appropriate confidence levels. The structured JSON output format from both `inference_agent.py` and Gemini ensures consistency across cases. The ability to clone the GitHub repository directly in Colab means all existing code (`inference_agent.py`, `config.py`, `launch_agent.py`) is immediately available without manual file transfers.\n",
    "\n",
    "**What Could Be Improved:**\n",
    "While the notebook currently uses simulated probabilities for demonstration, the `MelanomaAIAgent` class is ready to process actual images once a trained checkpoint is available. The integration could be tighter - currently we replicate some functions that exist in `inference_agent.py`; a better approach would be to import and extend the agent class directly. The `launch_agent.py` command-line interface could be adapted into an interactive Colab widget for easier case processing. The existing `_assess_quality()` method in `inference_agent.py` could be enhanced to provide feedback to Gemini about image quality concerns. Response parsing from Gemini could leverage the existing JSON export functions from `inference_agent.py` for consistency. The system would benefit from combining the ABCDE assessment logic already present in `inference_agent.py` with Gemini's contextual analysis to create a unified clinical reasoning explanation. Finally, the `process_batch()` function from `inference_agent.py` could be integrated with parallel Gemini API calls for efficient multi-case processing.\n",
    "\n",
    "---\n",
    "\n",
    "### Integration with Existing Codebase\n",
    "\n",
    "This notebook demonstrates how to combine:\n",
    "- **`inference_agent.py`**: Core CNN inference, ABCDE assessment, clinical report generation\n",
    "- **`config.py`**: Model configuration and hyperparameters  \n",
    "- **`launch_agent.py`**: Command-line interface for quick inference\n",
    "- **Gemini API**: Enhanced clinical reasoning and natural language generation\n",
    "\n",
    "The architecture preserves all functionality from the existing codebase while adding Gemini as an optional enhancement layer.\n",
    "\n",
    "---\n",
    "\n",
    "### Future Enhancements\n",
    "\n",
    "1. **Direct MelanomaAIAgent Extension**: Create a `GeminiEnhancedMelanomaAgent` class that inherits from `MelanomaAIAgent`\n",
    "2. **Real-time image upload and processing** using Colab's file upload widget\n",
    "3. **Integration with the existing `export_report()` function** for unified output formatting\n",
    "4. **Combine ABCDE assessments** from both `inference_agent.py` logic and Gemini reasoning\n",
    "5. **Batch processing** using `process_batch()` from `inference_agent.py` with parallel Gemini calls\n",
    "6. **Interactive web interface** adapting `launch_agent.py` logic into Streamlit app\n",
    "7. **Quality-aware prompting** that passes `_assess_quality()` results to Gemini for context\n",
    "\n",
    "---\n",
    "\n",
    "**Lab 1.5 Completed**: November 12, 2025  \n",
    "**Architecture**: ResNet-50 (inference_agent.py) + Gemini API  \n",
    "**Repository**: BinaryClassificationSystemFramework"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
